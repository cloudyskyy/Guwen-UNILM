### 三种预训练语言模型权重需要下载
- **BERT-base-chinese**:  [chinese_L-12_H-768_A-12](https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip)
- **RoBERTa-base-chinese**:  [chinese_roberta_wwm_ext_L-12_H-768_A-12](https://drive.google.com/open?id=1dtad0FFzG11CBsawu8hvwwzU2R0FDI94) 或去[Chinese-BERT-wwm](https://github.com/ymcui/Chinese-BERT-wwm)下载
- **_Guwenbert_** : [Guwenbert的开源版本](https://github.com/Ethan-yt/guwenbert)是pytorch权重，而本文使用的bert4keras是基于TensorFlow+keras框架，因此需要将pytorch权重转化为tf权重。可以自行转换为tf格式，也可以使用我转换的版本：[百度网盘](https://pan.baidu.com/s/1heS4B3wZypJjKuhtpIF7Lg) 提取码：vcdp

